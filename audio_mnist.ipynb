{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f858a04e-ab0a-42fd-9a78-bd90f2a2389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tqdm.notebook as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "import torchaudio\n",
    "import urllib\n",
    "import soundfile as sf\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b986c9",
   "metadata": {},
   "source": [
    "Создаем класс, в котором будут храниться сырые данные. При вызове __getitem__ происходит кодирование сырых данных в MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0018bbf0-ed00-40b7-a46f-c72423de5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRawDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.wav'):\n",
    "                class_label = int(file_name[0])  \n",
    "                self.files.append(os.path.join(folder_path, file_name))\n",
    "                self.labels.append(class_label)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        waveform, sample_rate = sf.read(file_path)\n",
    "        waveform = torch.tensor(waveform).float()\n",
    "        mfcc = torchaudio.transforms.MFCC(\n",
    "            sample_rate=sample_rate,\n",
    "            n_mfcc=13\n",
    "        )(waveform)\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            mfcc = self.transform(mfcc)\n",
    "            spectrogram = self.transform(spectrogram)\n",
    "\n",
    "        return mfcc, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0864e4",
   "metadata": {},
   "source": [
    "Данные можно скачать здесь: https://www.kaggle.com/datasets/joserzapata/free-spoken-digit-dataset-fsdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4115f560-49d9-470f-8bb2-eb16546ee519",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\Александр\\Downloads\\free-spoken-digit-dataset-v1.0.8\\Jakobovski-free-spoken-digit-dataset-e9e1155\\recordings'\n",
    "dataset = CustomRawDataset(folder_path, transform=None)\n",
    "ds_x = []\n",
    "ds_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7020f1ad-511a-48ff-9993-9979105bf734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 17])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1210][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61698539-8d4c-4ec4-b367-b2acfdbc9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    file, label = dataset[i]\n",
    "    ds_x.append(file)\n",
    "    ds_y.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae0fc2",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1838512d-849c-42c5-a2e7-ba5aaf850728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pad_2d(tensors):\n",
    "    max_cols = max(tensor.shape[1] for tensor in tensors)\n",
    "    padded_tensors = []\n",
    "    for tensor in tensors:\n",
    "        pad_width = max_cols - tensor.shape[1]\n",
    "        padding = (0, pad_width) \n",
    "        padded_tensor = torch.nn.functional.pad(tensor, padding, mode='constant', value=0)\n",
    "        padded_tensors.append(padded_tensor)\n",
    "    result = torch.stack(padded_tensors)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "451da88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_x = pad_2d(ds_x)\n",
    "ds_y = torch.tensor(ds_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f1e2563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 92])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_x[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e281750c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1500, 13, 92]), torch.Size([1500]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_x.shape, ds_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e0144",
   "metadata": {},
   "source": [
    "Создаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "144b3845-1d51-44fd-ba37-32244a90be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=32, kernel_size=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 48, kernel_size=2)\n",
    "        self.bn2 = nn.BatchNorm2d(48)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Размер входных данных для первого Dense слоя нужно определить после сверток и пуллинга\n",
    "        # Предположим, что входные размеры: (2, 13, 91)\n",
    "        # После первого Conv2d: (2, 12, 90)\n",
    "        # После второго Conv2d: (48, 11, 89)\n",
    "        # После MaxPool2d: (48, 5, 45)\n",
    "        # Размер для Flatten: 48 * 5 * 45 = 10800\n",
    "        self.fc1 = nn.Linear(10800, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.bn3(self.fc1(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn4(self.fc2(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "model = CNN1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a36b49d-6d8d-4087-8bfe-2dbff92561bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: torch.Size([1200, 13, 92]) torch.Size([1200])\n",
      "Размер тестовой выборки: torch.Size([300, 13, 92]) torch.Size([300])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ds_x_train, ds_x_test, ds_y_train, ds_y_test = train_test_split(ds_x, ds_y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Размер обучающей выборки:\", ds_x_train.shape, ds_y_train.shape)\n",
    "print(\"Размер тестовой выборки:\", ds_x_test.shape, ds_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61b00a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Александр\\AppData\\Local\\Temp\\ipykernel_25408\\4111692595.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x = torch.tensor(x, dtype=torch.float32)\n",
      "C:\\Users\\Александр\\AppData\\Local\\Temp\\ipykernel_25408\\4111692595.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long) \n",
    "        if self.x.ndim == 3:  \n",
    "            self.x = self.x.unsqueeze(1)  \n",
    "            self.x = torch.cat([self.x, self.x], dim=1) \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "train_dataset = CustomDataset(ds_x_train, ds_y_train)\n",
    "test_dataset = CustomDataset(ds_x_test, ds_y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f0fc6",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02ca37ae-0164-4d36-9ee1-46e0e5eed7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] - Loss: 2.1392, Train Accuracy: 53.00%, Test Accuracy: 72.00%\n",
      "Epoch [2/15] - Loss: 1.8581, Train Accuracy: 87.08%, Test Accuracy: 95.33%\n",
      "Epoch [3/15] - Loss: 1.6812, Train Accuracy: 93.83%, Test Accuracy: 96.00%\n",
      "Epoch [4/15] - Loss: 1.5956, Train Accuracy: 96.25%, Test Accuracy: 96.00%\n",
      "Epoch [5/15] - Loss: 1.5636, Train Accuracy: 96.67%, Test Accuracy: 98.00%\n",
      "Epoch [6/15] - Loss: 1.5345, Train Accuracy: 97.33%, Test Accuracy: 98.00%\n",
      "Epoch [7/15] - Loss: 1.5187, Train Accuracy: 97.75%, Test Accuracy: 97.33%\n",
      "Epoch [8/15] - Loss: 1.5054, Train Accuracy: 98.50%, Test Accuracy: 98.33%\n",
      "Epoch [9/15] - Loss: 1.4986, Train Accuracy: 98.67%, Test Accuracy: 96.33%\n",
      "Epoch [10/15] - Loss: 1.4919, Train Accuracy: 98.83%, Test Accuracy: 97.67%\n",
      "Epoch [11/15] - Loss: 1.4888, Train Accuracy: 98.92%, Test Accuracy: 97.00%\n",
      "Epoch [12/15] - Loss: 1.4907, Train Accuracy: 99.33%, Test Accuracy: 97.33%\n",
      "Epoch [13/15] - Loss: 1.4859, Train Accuracy: 99.00%, Test Accuracy: 98.33%\n",
      "Epoch [14/15] - Loss: 1.4821, Train Accuracy: 99.25%, Test Accuracy: 96.67%\n",
      "Epoch [15/15] - Loss: 1.4821, Train Accuracy: 99.25%, Test Accuracy: 98.33%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs, labels\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    \n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "    test_acc = 100.0 * test_correct / test_total\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.2f}%, Test Accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1ddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
